[
  {
    "model_type": "Dense",
    "model_name": "Llama3-8B",
    "parameters": {
      "model_total_params": 8000000000,
      "vocab_size": 128000,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Llama3-70B",
    "parameters": {
      "model_total_params": 70000000000,
      "vocab_size": 128000,
      "hidden_size": 8192,
      "num_hidden_layers": 80,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Llama2-7B",
    "parameters": {
      "model_total_params": 7000000000,
      "vocab_size": 32000,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Llama2-13B",
    "parameters": {
      "model_total_params": 13000000000,
      "vocab_size": 32000,
      "hidden_size": 5120,
      "num_hidden_layers": 40,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Llama2-70B",
    "parameters": {
      "model_total_params": 70000000000,
      "vocab_size": 32000,
      "hidden_size": 8192,
      "num_hidden_layers": 80,
      "num_attention_heads": 64,
      "num_key_value_heads": 64,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Baichuan2-13B",
    "parameters": {
      "model_total_params": 13000000000,
      "vocab_size": 125696,
      "hidden_size": 5120,
      "num_hidden_layers": 40,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Qwen2-7B",
    "parameters": {
      "model_total_params": 7000000000,
      "vocab_size": 151936,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 4,
      "max_position_embeddings": 32768
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Qwen2-72B",
    "parameters": {
      "model_total_params": 72000000000,
      "vocab_size": 151936,
      "hidden_size": 8192,
      "num_hidden_layers": 80,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Yi-34B",
    "parameters": {
      "model_total_params": 34000000000,
      "vocab_size": 64000,
      "hidden_size": 7168,
      "num_hidden_layers": 60,
      "num_attention_heads": 56,
      "num_key_value_heads": 8,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Mixtral-8x7B",
    "parameters": {
      "model_total_params": 46700000000,
      "expert_params_per_expert": 4500000000,
      "shared_params": 10700000000,
      "vocab_size": 32000,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "intermediate_size": 14336,
      "num_local_experts": 8,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 32768,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Mixtral-8x22B",
    "parameters": {
      "model_total_params": 141700000000,
      "expert_params_per_expert": 14000000000,
      "shared_params": 29700000000,
      "vocab_size": 32000,
      "hidden_size": 6144,
      "num_hidden_layers": 48,
      "num_attention_heads": 48,
      "num_key_value_heads": 8,
      "intermediate_size": 21504,
      "num_local_experts": 8,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 32768,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Qwen1.5-MoE-A2.7B",
    "parameters": {
      "model_total_params": 8100000000,
      "expert_params_per_expert": 1350000000,
      "shared_params": 2700000000,
      "vocab_size": 151936,
      "hidden_size": 2048,
      "num_hidden_layers": 24,
      "num_attention_heads": 16,
      "num_key_value_heads": 4,
      "intermediate_size": 7168,
      "num_local_experts": 4,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 32768,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Qwen1.5-MoE-A5.8B",
    "parameters": {
      "model_total_params": 14500000000,
      "expert_params_per_expert": 2175000000,
      "shared_params": 5800000000,
      "vocab_size": 151936,
      "hidden_size": 3072,
      "num_hidden_layers": 28,
      "num_attention_heads": 24,
      "num_key_value_heads": 6,
      "intermediate_size": 10752,
      "num_local_experts": 4,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 32768,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "MoE",
    "model_name": "GLM-4-MoE",
    "parameters": {
      "model_total_params": 43000000000,
      "expert_params_per_expert": 4000000000,
      "shared_params": 11000000000,
      "vocab_size": 100000,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "intermediate_size": 14336,
      "num_local_experts": 8,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 32768,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Grok-1",
    "parameters": {
      "model_total_params": 314000000000,
      "expert_params_per_expert": 25000000000,
      "shared_params": 114000000000,
      "vocab_size": 128000,
      "hidden_size": 8192,
      "num_hidden_layers": 64,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "intermediate_size": 28672,
      "num_local_experts": 8,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 8192,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "llava-1.5-7b",
    "parameters": {
      "llm_base_params": 6738415616,
      "vision_params": 309006848,
      "audio_params": 100000000,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 128256,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "max_position_embeddings": 4096,
      "image_input_size": 336,
      "patch_size": 14,
      "audio_input_length": 30,
      "audio_sample_rate": 16000
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "llava-1.5-13b",
    "parameters": {
      "llm_base_params": 13000000000,
      "vision_params": 309006848,
      "audio_params": 100000000,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 128256,
      "hidden_size": 5120,
      "num_hidden_layers": 40,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 4096,
      "image_input_size": 336,
      "patch_size": 14,
      "audio_input_length": 30,
      "audio_sample_rate": 16000
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "GPT-4V",
    "parameters": {
      "llm_base_params": 1500000000000,
      "vision_params": 5000000000,
      "audio_params": 0,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 100000,
      "hidden_size": 12288,
      "num_hidden_layers": 96,
      "num_attention_heads": 96,
      "num_key_value_heads": 12,
      "max_position_embeddings": 128000,
      "image_input_size": 448,
      "patch_size": 14,
      "audio_input_length": 0,
      "audio_sample_rate": 0
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "Claude3-Opus-Multimodal",
    "parameters": {
      "llm_base_params": 175000000000,
      "vision_params": 5000000000,
      "audio_params": 0,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 100000,
      "hidden_size": 12288,
      "num_hidden_layers": 96,
      "num_attention_heads": 96,
      "num_key_value_heads": 12,
      "max_position_embeddings": 200000,
      "image_input_size": 448,
      "patch_size": 14,
      "audio_input_length": 0,
      "audio_sample_rate": 0
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "Qwen-VL",
    "parameters": {
      "llm_base_params": 7000000000,
      "vision_params": 600000000,
      "audio_params": 0,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 151936,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "max_position_embeddings": 32768,
      "image_input_size": 448,
      "patch_size": 14,
      "audio_input_length": 0,
      "audio_sample_rate": 0
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "Yi-VL-34B",
    "parameters": {
      "llm_base_params": 34000000000,
      "vision_params": 600000000,
      "audio_params": 0,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 64000,
      "hidden_size": 7168,
      "num_hidden_layers": 60,
      "num_attention_heads": 56,
      "num_key_value_heads": 8,
      "max_position_embeddings": 4096,
      "image_input_size": 336,
      "patch_size": 14,
      "audio_input_length": 0,
      "audio_sample_rate": 0
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "Gemini-Pro-Vision",
    "parameters": {
      "llm_base_params": 175000000000,
      "vision_params": 5000000000,
      "audio_params": 1000000000,
      "has_vision_modal": true,
      "has_audio_modal": true,
      "vocab_size": 256000,
      "hidden_size": 12288,
      "num_hidden_layers": 96,
      "num_attention_heads": 96,
      "num_key_value_heads": 12,
      "max_position_embeddings": 32768,
      "image_input_size": 448,
      "patch_size": 14,
      "audio_input_length": 30,
      "audio_sample_rate": 16000
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "Gemini-Ultra-Vision",
    "parameters": {
      "llm_base_params": 1500000000000,
      "vision_params": 10000000000,
      "audio_params": 2000000000,
      "has_vision_modal": true,
      "has_audio_modal": true,
      "vocab_size": 256000,
      "hidden_size": 18432,
      "num_hidden_layers": 120,
      "num_attention_heads": 128,
      "num_key_value_heads": 16,
      "max_position_embeddings": 32768,
      "image_input_size": 448,
      "patch_size": 14,
      "audio_input_length": 30,
      "audio_sample_rate": 16000
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "CogVLM-17B",
    "parameters": {
      "llm_base_params": 17000000000,
      "vision_params": 1000000000,
      "audio_params": 0,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 100000,
      "hidden_size": 6144,
      "num_hidden_layers": 40,
      "num_attention_heads": 48,
      "num_key_value_heads": 48,
      "max_position_embeddings": 4096,
      "image_input_size": 448,
      "patch_size": 14,
      "audio_input_length": 0,
      "audio_sample_rate": 0
    }
  }
]