[
  {
    "model_type": "Dense",
    "model_name": "Llama3-8B",
    "parameters": {
      "model_total_params": 8000000000,
      "vocab_size": 128256,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 8192
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Llama3-70B",
    "parameters": {
      "model_total_params": 70000000000,
      "vocab_size": 128256,
      "hidden_size": 8192,
      "num_hidden_layers": 80,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 8192
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Llama2-7B",
    "parameters": {
      "model_total_params": 7000000000,
      "vocab_size": 32000,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Llama2-13B",
    "parameters": {
      "model_total_params": 13000000000,
      "vocab_size": 32000,
      "hidden_size": 5120,
      "num_hidden_layers": 40,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Llama2-70B",
    "parameters": {
      "model_total_params": 70000000000,
      "vocab_size": 32000,
      "hidden_size": 8192,
      "num_hidden_layers": 80,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Baichuan2-13B",
    "parameters": {
      "model_total_params": 13000000000,
      "vocab_size": 125696,
      "hidden_size": 5120,
      "num_hidden_layers": 40,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Qwen2-7B",
    "parameters": {
      "model_total_params": 7000000000,
      "vocab_size": 152064,
      "hidden_size": 3584,
      "num_hidden_layers": 28,
      "num_attention_heads": 28,
      "num_key_value_heads": 4,
      "max_position_embeddings": 32768
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Qwen2-72B",
    "parameters": {
      "model_total_params": 72000000000,
      "vocab_size": 152064,
      "hidden_size": 8192,
      "num_hidden_layers": 80,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768
    }
  },
  {
    "model_type": "Dense",
    "model_name": "Yi-34B",
    "parameters": {
      "model_total_params": 34000000000,
      "vocab_size": 64000,
      "hidden_size": 7168,
      "num_hidden_layers": 60,
      "num_attention_heads": 56,
      "num_key_value_heads": 8,
      "max_position_embeddings": 4096
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Mixtral-8x7B",
    "parameters": {
      "model_total_params": 46700000000,
      "expert_params_per_expert": 3775000000,
      "shared_params": 1070000000,
      "vocab_size": 32000,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "intermediate_size": 14336,
      "num_local_experts": 8,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 32768,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Mixtral-8x22B",
    "parameters": {
      "model_total_params": 141700000000,
      "expert_params_per_expert": 14000000000,
      "shared_params": 29700000000,
      "vocab_size": 32768,
      "hidden_size": 6144,
      "num_hidden_layers": 56,
      "num_attention_heads": 48,
      "num_key_value_heads": 8,
      "intermediate_size": 16384,
      "num_local_experts": 8,
      "num_experts_per_tok": 2,
      "max_position_embeddings": 65536,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Qwen1.5-MoE-A2.7B",
    "parameters": {
      "model_total_params": 8100000000,
      "expert_params_per_expert": 1350000000,
      "shared_params": 2700000000,
      "vocab_size": 151936,
      "hidden_size": 2048,
      "num_hidden_layers": 24,
      "num_attention_heads": 16,
      "num_key_value_heads": 16,
      "intermediate_size": 5632,
      "num_local_experts": 60,
      "num_experts_per_tok": 4,
      "max_position_embeddings": 32768,
      "input_length": 2048,
      "output_length": 2048
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "llava-1.5-7b",
    "parameters": {
      "llm_base_params": 6738415616,
      "vision_params": 309006848,
      "audio_params": 0,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 32000,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "max_position_embeddings": 4096,
      "image_input_size": 336,
      "patch_size": 14,
      "audio_input_length": 30,
      "audio_sample_rate": 16000
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "llava-1.5-13b",
    "parameters": {
      "llm_base_params": 13000000000,
      "vision_params": 309006848,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 32064,
      "hidden_size": 5120,
      "num_hidden_layers": 40,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 4096,
      "image_input_size": 336,
      "patch_size": 14
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "Qwen2-VL-72B",
    "parameters": {
      "llm_base_params": 7000000000,
      "vision_params": 600000000,
      "audio_params": 0,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 152064,
      "hidden_size": 8192,
      "num_hidden_layers": 80,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768,
      "image_input_size": 448,
      "patch_size": 14,
      "audio_input_length": 0,
      "audio_sample_rate": 0
    }
  },
  {
    "model_type": "Multimodal",
    "model_name": "Yi-VL-34B",
    "parameters": {
      "llm_base_params": 34000000000,
      "vision_params": 600000000,
      "audio_params": 0,
      "has_vision_modal": true,
      "has_audio_modal": false,
      "vocab_size": 64000,
      "hidden_size": 7168,
      "num_hidden_layers": 60,
      "num_attention_heads": 56,
      "num_key_value_heads": 8,
      "max_position_embeddings": 4096,
      "image_input_size": 448,
      "patch_size": 14,
      "audio_input_length": 0,
      "audio_sample_rate": 0
    }
  },
  {
    "model_type": "MoE",
    "model_name": "Deepseek-V3",
    "parameters": {
      "model_total_params": 821000000000,
      "expert_params_per_expert": 2642000000,
      "shared_params": 14450000000,
      "vocab_size": 129280,
      "hidden_size": 7168,
      "num_hidden_layers": 61,
      "num_attention_heads": 128,
      "num_key_value_heads": 128,
      "intermediate_size": 18432,
      "num_local_experts": 256,
      "num_experts_per_tok": 8,
      "max_position_embeddings": 163840,
      "input_length": 163840,
      "output_length": 163840
    }
  },
  {
    "model_type": "Dense",
    "model_name": "DeepSeek-R1-Distill-Llama-70B",
    "parameters": {
      "model_total_params": 70000000000,
      "vocab_size": 128256,
      "hidden_size": 8192,
      "num_hidden_layers": 80,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    }
  },
  {
    "model_type": "Dense",
    "model_name": "DeepSeek-R1-Distill-Qwen-32B",
    "parameters": {
      "model_total_params": 32000000000,
      "vocab_size": 152064,
      "hidden_size": 5120,
      "num_hidden_layers": 64,
      "num_attention_heads": 40,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    }
  },
  {
    "model_type": "Dense",
    "model_name": "DeepSeek-R1-Distill-Qwen-14B",
    "parameters": {
      "model_total_params": 14000000000,
      "vocab_size": 152064,
      "hidden_size": 5120,
      "num_hidden_layers": 48,
      "num_attention_heads": 40,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    }
  },
  {
    "model_type": "Dense",
    "model_name": "DeepSeek-R1-Distill-Llama-8B ",
    "parameters": {
      "model_total_params": 8000000000,
      "vocab_size": 128256,
      "hidden_size": 4096,
      "num_hidden_layers": 32,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 8192
    }
  },
  {
    "model_type": "Dense",
    "model_name": "DeepSeek-R1-Distill-Qwen-7B",
    "parameters": {
      "model_total_params": 7000000000,
      "vocab_size": 152064,
      "hidden_size": 3584,
      "num_hidden_layers": 28,
      "num_attention_heads": 28,
      "num_key_value_heads": 4,
      "max_position_embeddings": 131072
    }
  },
  {
    "model_type": "Dense",
    "model_name": "DeepSeek-R1-Distill-Qwen-1.5B",
    "parameters": {
      "model_total_params": 1500000000,
      "vocab_size": 151936,
      "hidden_size": 1536,
      "num_hidden_layers": 28,
      "num_attention_heads": 12,
      "num_key_value_heads": 2,
      "max_position_embeddings": 131072
    }
  },
  {
    "model_type": "Dense",
    "model_name": "DeepSeek-R1-0528-Qwen3-8B",
    "parameters": {
      "model_total_params": 8000000000,
      "vocab_size": 151936,
      "hidden_size": 4096,
      "num_hidden_layers": 36,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    }
  }
]